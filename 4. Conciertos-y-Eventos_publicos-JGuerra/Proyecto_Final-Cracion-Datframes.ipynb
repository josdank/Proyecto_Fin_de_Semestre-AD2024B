{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc24fb-35f2-4e25-8854-f63bbc706a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- Creación DATAFRAMES ------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a5afa-9184-4e66-a28a-01e2e9944692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de biblioteca para la codificación de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3100a2e1-3526-47c7-a905-7359b2c95653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in c:\\python312\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: wcwidth in c:\\python312\\lib\\site-packages (from ftfy) (0.2.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902ac5b-0c8f-452a-8548-6a3ceeebc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 1: Leer Datos de MongoDB, Exportar a JSON y CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82323fb5-3f71-4844-8edb-7007c53c85ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josug\\AppData\\Local\\Temp\\ipykernel_12780\\996111633.py:40: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_mongo = df_mongo.applymap(convert_objectid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame combinado exportado a df_json\\final_combined_dataframe.json y df_csv\\final_combined_dataframe.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "from bson import ObjectId\n",
    "\n",
    "# Conexión a MongoDB\n",
    "client = MongoClient('mongodb+srv://Safron:Safron1234@cluster0.vnngk.mongodb.net/', serverSelectionTimeoutMS=5000)\n",
    "db = client['world_cup_data']\n",
    "\n",
    "# Función para leer registros de MongoDB en fragmentos más pequeños\n",
    "def read_mongo(collection_name, batch_size=5000):\n",
    "    collection = db[collection_name]\n",
    "    data = []\n",
    "    skip = 0\n",
    "    while True:\n",
    "        batch = list(collection.find().skip(skip).limit(batch_size))\n",
    "        if not batch:\n",
    "            break\n",
    "        data.extend(batch)\n",
    "        skip += batch_size\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Función para convertir ObjectId a cadena\n",
    "def convert_objectid(x):\n",
    "    if isinstance(x, ObjectId):\n",
    "        return str(x)\n",
    "    return x\n",
    "\n",
    "# Listas para almacenar los dataframes\n",
    "dataframes = []\n",
    "collection_names = ['actions', 'events_World_Cup', 'features', 'games', 'player_games', 'playerank', 'players']\n",
    "\n",
    "# Leer registros y combinar dataframes\n",
    "for collection_name in collection_names:\n",
    "    df_mongo = read_mongo(collection_name)\n",
    "    \n",
    "    # Convertir ObjectId a cadena\n",
    "    df_mongo = df_mongo.applymap(convert_objectid)\n",
    "    \n",
    "    # Rellenar valores NaN con datos similares usando interpolación\n",
    "    df_mongo = df_mongo.ffill().bfill()\n",
    "    \n",
    "    # Excluir registros con valores NaN\n",
    "    df_mongo = df_mongo.dropna()\n",
    "    \n",
    "    # Agregar el dataframe a la lista\n",
    "    dataframes.append(df_mongo)\n",
    "\n",
    "# Combinar todos los dataframes en uno solo\n",
    "final_combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Crear carpetas para almacenar los archivos si no existen\n",
    "os.makedirs('df_json', exist_ok=True)\n",
    "os.makedirs('df_csv', exist_ok=True)\n",
    "\n",
    "# Exportar el dataframe combinado a formatos JSON y CSV\n",
    "json_filename = os.path.join('df_json', \"final_combined_dataframe.json\")\n",
    "with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_combined_df.to_dict(orient='records'), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "csv_filename = os.path.join('df_csv', \"final_combined_dataframe.csv\")\n",
    "final_combined_df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"DataFrame combinado exportado a {json_filename} y {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef1a76-c190-4a9b-bf2c-37e793954267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Leer los Archivos CSV y Convertirlos a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aabf34b-ae50-4658-b924-49b3fc29315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josug\\AppData\\Local\\Temp\\ipykernel_12780\\467854512.py:8: DtypeWarning: Columns (16,17,18,20,21,23,25,27,31,48,49,50,64,65,66,80,81,82,84,85,126,130,131,132,133,134,137,140,142,144,145,147,149,150,152,153) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV combinado convertido a JSON y exportado a df_json\\converted_from_csv_combined.json\n"
     ]
    }
   ],
   "source": [
    "# Lista de nombres de archivos CSV\n",
    "csv_files = [\"df_csv/final_combined_dataframe.csv\"]\n",
    "\n",
    "# Leer y convertir los archivos CSV a JSON\n",
    "for csv_file in csv_files:\n",
    "    if os.path.exists(csv_file):\n",
    "        # Leer el archivo CSV\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "        \n",
    "        # Exportar a JSON\n",
    "        json_filename = os.path.join('df_json', \"converted_from_csv_combined.json\")\n",
    "        with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(df.to_dict(orient='records'), f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        print(f\"CSV combinado convertido a JSON y exportado a {json_filename}\")\n",
    "    else:\n",
    "        print(f\"El archivo {csv_file} no existe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd2182-8693-4eb6-afef-c8f4bebe9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Leer el Archivo JSON y Convertirlo a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca39df3-192a-4db0-9a08-7a0d0c03e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON combinado convertido a CSV y exportado a df_csv\\final_combined_from_json.csv\n"
     ]
    }
   ],
   "source": [
    "# Lista de nombres de archivos JSON combinados\n",
    "combined_json_files = [\"df_json/converted_from_csv_combined.json\"]\n",
    "\n",
    "# Leer y convertir el archivo JSON a CSV\n",
    "for json_file in combined_json_files:\n",
    "    if os.path.exists(json_file):\n",
    "        # Leer el archivo JSON\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame(data)\n",
    "        \n",
    "        # Exportar a CSV\n",
    "        csv_filename = os.path.join('df_csv', \"final_combined_from_json.csv\")\n",
    "        df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"JSON combinado convertido a CSV y exportado a {csv_filename}\")\n",
    "    else:\n",
    "        print(f\"El archivo {json_file} no existe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8c5b8-0512-4087-a43e-eb67967dee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Eliminar Archivos Anteriores y Dejar Solo el JSON y CSV Combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "311916ed-dfe1-4d03-b698-3f982454aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos anteriores eliminados. Solo quedan el JSON y CSV combinados.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Eliminar archivos JSON y CSV anteriores\n",
    "json_files_to_delete = glob.glob('df_json/final_dataframe_*.json')\n",
    "csv_files_to_delete = glob.glob('df_csv/final_dataframe_*.csv')\n",
    "\n",
    "for file in json_files_to_delete + csv_files_to_delete:\n",
    "    os.remove(file)\n",
    "    print(f\"Archivo eliminado: {file}\")\n",
    "\n",
    "# Dejar solo el JSON y CSV combinados\n",
    "print(\"Archivos anteriores eliminados. Solo quedan el JSON y CSV combinados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf9d93-203b-4367-a4b1-2cfc500c2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Mostrar los Primeros 10 Registros del Archivo JSON Combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d56e517-ce47-4cba-b197-b33bdf3e6113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 10 registros del DataFrame combinado (JSON):\n",
      "                        _id  Unnamed: 0    game_id  period_id  time_seconds  \\\n",
      "0  679b047032822233cc19e2ad     20000.0  2500026.0        2.0    381.385169   \n",
      "1  679b047032822233cc19e2ae     20001.0  2500026.0        2.0    384.490390   \n",
      "2  679b047032822233cc19e2af     20002.0  2500026.0        2.0    386.561951   \n",
      "3  679b047032822233cc19e2b0     20003.0  2500026.0        2.0    386.759963   \n",
      "4  679b047032822233cc19e2b1     20004.0  2500026.0        2.0    388.934157   \n",
      "5  679b047032822233cc19e2b2     20005.0  2500026.0        2.0    392.057843   \n",
      "6  679b047032822233cc19e2b3     20006.0  2500026.0        2.0    394.949059   \n",
      "7  679b047032822233cc19e2b4     20007.0  2500026.0        2.0    398.314063   \n",
      "8  679b047032822233cc19e2b5     20008.0  2500026.0        2.0    401.679067   \n",
      "9  679b047032822233cc19e2b6     20009.0  2500026.0        2.0    404.461242   \n",
      "\n",
      "   team_id  player_id  start_x  start_y  end_x  ...  lastName  currentTeamId  \\\n",
      "0   1619.0   135114.0    64.05    33.32  75.60  ...       NaN            NaN   \n",
      "1   1619.0   240032.0    75.60    41.48  68.25  ...       NaN            NaN   \n",
      "2   1619.0    70389.0    68.25    61.20  64.05  ...       NaN            NaN   \n",
      "3   1619.0   135114.0    64.05    51.68  70.35  ...       NaN            NaN   \n",
      "4   1619.0   240032.0    70.35    48.28  75.60  ...       NaN            NaN   \n",
      "5   1619.0     8136.0    75.60    29.24  74.55  ...       NaN            NaN   \n",
      "6   1619.0   268776.0    74.55    12.92  42.00  ...       NaN            NaN   \n",
      "7   1619.0      383.0    42.00    17.68  31.50  ...       NaN            NaN   \n",
      "8   1619.0      383.0    31.50    34.00  21.00  ...       NaN            NaN   \n",
      "9   1619.0     8953.0    21.00    46.24   0.00  ...       NaN            NaN   \n",
      "\n",
      "   birthDate  height  role  birthArea wyId foot shortName  \\\n",
      "0        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "1        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "2        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "3        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "4        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "5        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "6        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "7        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "8        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "9        NaN     NaN   NaN        NaN  NaN  NaN       NaN   \n",
      "\n",
      "   currentNationalTeamId  \n",
      "0                    NaN  \n",
      "1                    NaN  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4                    NaN  \n",
      "5                    NaN  \n",
      "6                    NaN  \n",
      "7                    NaN  \n",
      "8                    NaN  \n",
      "9                    NaN  \n",
      "\n",
      "[10 rows x 155 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lista de nombres de archivos JSON combinados\n",
    "combined_json_files = [\"df_json/converted_from_csv_combined.json\"]\n",
    "\n",
    "# Leer y mostrar los primeros 10 registros del archivo JSON combinado\n",
    "for json_file in combined_json_files:\n",
    "    if os.path.exists(json_file):\n",
    "        # Leer el archivo JSON\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame(data)\n",
    "        \n",
    "        # Mostrar los primeros 10 registros\n",
    "        print(\"Primeros 10 registros del DataFrame combinado (JSON):\")\n",
    "        print(df.head(10))\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"El archivo {json_file} no existe.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
