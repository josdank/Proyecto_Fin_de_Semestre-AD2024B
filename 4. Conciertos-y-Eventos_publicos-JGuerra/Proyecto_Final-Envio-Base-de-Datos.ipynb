{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7a31e-1838-4f7c-92b8-3de0629dfbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------- ENVÍO A BASES DE DATOS ------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5b5c31-235f-4870-a02a-772a0a9566aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\python312\\lib\\site-packages (2.0.37)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python312\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\python312\\lib\\site-packages (from sqlalchemy) (4.12.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\python312\\lib\\site-packages (2.9.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3c80c-4efd-46e8-9311-d70bbf16bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------- Verificación en donde se encuentra ejecutnadose el archivo --------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9eba36-4beb-4056-b271-6cebc026a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Documentos\\4to Semestre\\Analisis_de_Datos\\Bases_JG\\Proyecto_Final\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d6050-d095-40ce-8277-4c5ecd921011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------- Registros en Bases de DATOS --------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df2befcd-0f12-4190-a4e4-f87dfffa4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos SQLite creada correctamente\n",
      "Cargando archivo: archivos_limpios\\limpio_actions.csv\n",
      "Cargando archivo: archivos_limpios\\limpio_events_World_Cup.csv\n",
      "Cargando archivo: archivos_limpios\\limpio_features.csv\n",
      "Cargando archivo: archivos_limpios\\limpio_games.csv\n",
      "Cargando archivo: archivos_limpios\\limpio_player_games.csv\n",
      "Límite máximo de registros alcanzado en todas las bases de datos.\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n",
    "import sqlite3\n",
    "import gc  # Para liberar memoria\n",
    "\n",
    "# Configuración de las conexiones\n",
    "\n",
    "## MongoDB\n",
    "client = MongoClient('mongodb+srv://Safron:Safron1234@cluster0.vnngk.mongodb.net/')\n",
    "db = client['world_cup_data']\n",
    "\n",
    "## SQLite\n",
    "sqlite_conn = sqlite3.connect('world_cup.db') \n",
    "print(\"Base de datos SQLite creada correctamente\")\n",
    "\n",
    "## PostgreSQL\n",
    "postgresql_engine = create_engine('postgresql://postgres:123456@localhost/world_cup')\n",
    "\n",
    "# Carpeta donde están los archivos limpios\n",
    "output_folder = 'archivos_limpios'\n",
    "files = ['limpio_actions.csv', 'limpio_events_World_Cup.csv', 'limpio_features.csv', 'limpio_games.csv', 'limpio_player_games.csv', 'limpio_playerank.csv', 'limpio_players.csv']\n",
    "\n",
    "# Inicializar contadores de registros totales por base de datos\n",
    "mongo_total_count = 0\n",
    "sqlite_total_count = 0\n",
    "postgres_total_count = 0\n",
    "\n",
    "# Limite máximo de registros por archivo y por base de datos\n",
    "max_records_per_file = 50000\n",
    "max_records_per_db = 200000\n",
    "\n",
    "# Procesar cada archivo\n",
    "for file in files:\n",
    "    file_path = os.path.join(output_folder, file)\n",
    "    \n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Archivo no encontrado: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Cargando archivo: {file_path}\")\n",
    "\n",
    "    # Cargar el archivo en fragmentos y limitar a 50,000 registros\n",
    "    chunksize = 10000  # Número de filas por fragmento\n",
    "    table_name = file.split('.')[0].replace('limpio_', '')  # Eliminar el prefijo 'limpio_' para obtener el nombre base de la tabla/colección\n",
    "    records_count = 0\n",
    "\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=True):\n",
    "        if records_count + len(chunk) > max_records_per_file:\n",
    "            chunk = chunk.iloc[:max_records_per_file - records_count]  # Limitar a 50,000 registros por archivo\n",
    "\n",
    "        if not chunk.empty:  # Solo intentar insertar si el chunk no está vacío\n",
    "            if mongo_total_count < max_records_per_db:\n",
    "                try:\n",
    "                    # Guardar en MongoDB\n",
    "                    collection = db[table_name]\n",
    "                    collection.insert_many(chunk.to_dict(orient='records'))\n",
    "                    mongo_total_count += len(chunk)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al insertar en MongoDB: {e}\")\n",
    "\n",
    "            if sqlite_total_count < max_records_per_db:\n",
    "                try:\n",
    "                    # Guardar en SQLite\n",
    "                    chunk.to_sql(table_name, sqlite_conn, index=False, if_exists='append')\n",
    "                    sqlite_total_count += len(chunk)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al insertar en SQLite: {e}\")\n",
    "\n",
    "            if postgres_total_count < max_records_per_db:\n",
    "                try:\n",
    "                    # Guardar en PostgreSQL\n",
    "                    chunk.to_sql(table_name, postgresql_engine, index=False, if_exists='append')\n",
    "                    postgres_total_count += len(chunk)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al insertar en PostgreSQL: {e}\")\n",
    "\n",
    "            records_count += len(chunk)\n",
    "\n",
    "        # Verificar si hemos alcanzado el máximo de registros por base de datos\n",
    "        if mongo_total_count >= max_records_per_db and sqlite_total_count >= max_records_per_db and postgres_total_count >= max_records_per_db:\n",
    "            print(\"Límite máximo de registros alcanzado en todas las bases de datos.\")\n",
    "            break\n",
    "\n",
    "        # Liberar memoria\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "    if mongo_total_count >= max_records_per_db and sqlite_total_count >= max_records_per_db and postgres_total_count >= max_records_per_db:\n",
    "        break\n",
    "\n",
    "# Cerrar conexiones\n",
    "sqlite_conn.commit()\n",
    "sqlite_conn.close()\n",
    "client.close()\n",
    "postgresql_engine.dispose()\n",
    "\n",
    "print(\"Proceso completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081d54f-728b-43fd-90c2-f795e465984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------- Inserción de registros extra -----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08547a76-78cc-4b11-b879-66acf2e96c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos SQLite creada correctamente\n",
      "Cargando archivo: archivos_limpios\\limpio_playerank.csv\n",
      "Insertados 2000 registros en MongoDB para playerank.\n",
      "Insertados 2000 registros en SQLite para playerank.\n",
      "Insertados 2000 registros en PostgreSQL para playerank.\n",
      "Límite de 2000 registros alcanzado para limpio_playerank.csv.\n",
      "Cargando archivo: archivos_limpios\\limpio_players.csv\n",
      "Insertados 2000 registros en MongoDB para players.\n",
      "Insertados 2000 registros en SQLite para players.\n",
      "Insertados 2000 registros en PostgreSQL para players.\n",
      "Límite de 2000 registros alcanzado para limpio_players.csv.\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n",
    "import sqlite3\n",
    "import gc  # Para liberar memoria\n",
    "\n",
    "# Configuración de las conexiones\n",
    "\n",
    "## MongoDB\n",
    "client = MongoClient('mongodb+srv://Safron:Safron1234@cluster0.vnngk.mongodb.net/')\n",
    "db = client['world_cup_data']\n",
    "\n",
    "## SQLite\n",
    "sqlite_conn = sqlite3.connect('world_cup.db') \n",
    "print(\"Base de datos SQLite creada correctamente\")\n",
    "\n",
    "## PostgreSQL\n",
    "postgresql_engine = create_engine('postgresql://postgres:123456@localhost/world_cup')\n",
    "\n",
    "# Carpeta donde están los archivos limpios\n",
    "output_folder = 'archivos_limpios'\n",
    "files = ['limpio_playerank.csv', 'limpio_players.csv']  \n",
    "\n",
    "# Número máximo de registros adicionales\n",
    "max_additional_records = 2000\n",
    "\n",
    "# Procesar cada archivo\n",
    "for file in files:\n",
    "    file_path = os.path.join(output_folder, file)\n",
    "    \n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Archivo no encontrado: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Cargando archivo: {file_path}\")\n",
    "\n",
    "    # Cargar el archivo y limitar a 2000 registros adicionales\n",
    "    table_name = file.split('.')[0].replace('limpio_', '')  # Eliminar el prefijo 'limpio_' para obtener el nombre base de la tabla/colección\n",
    "    records_count = 0\n",
    "\n",
    "    for chunk in pd.read_csv(file_path, chunksize=max_additional_records, low_memory=True):\n",
    "        if records_count + len(chunk) > max_additional_records:\n",
    "            chunk = chunk.iloc[:max_additional_records - records_count]  # Limitar a 2000 registros adicionales por archivo\n",
    "\n",
    "        if not chunk.empty:  # Solo intentar insertar si el chunk no está vacío\n",
    "            try:\n",
    "                # Guardar en MongoDB\n",
    "                collection = db[table_name]\n",
    "                collection.insert_many(chunk.to_dict(orient='records'))\n",
    "                print(f\"Insertados {len(chunk)} registros en MongoDB para {table_name}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al insertar en MongoDB: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Guardar en SQLite\n",
    "                chunk.to_sql(table_name, sqlite_conn, index=False, if_exists='append')\n",
    "                print(f\"Insertados {len(chunk)} registros en SQLite para {table_name}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al insertar en SQLite: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Guardar en PostgreSQL\n",
    "                chunk.to_sql(table_name, postgresql_engine, index=False, if_exists='append')\n",
    "                print(f\"Insertados {len(chunk)} registros en PostgreSQL para {table_name}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al insertar en PostgreSQL: {e}\")\n",
    "\n",
    "            records_count += len(chunk)\n",
    "\n",
    "        if records_count >= max_additional_records:\n",
    "            print(f\"Límite de {max_additional_records} registros alcanzado para {file}.\")\n",
    "            break\n",
    "\n",
    "        # Liberar memoria\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "# Cerrar conexiones\n",
    "sqlite_conn.commit()\n",
    "sqlite_conn.close()\n",
    "client.close()\n",
    "postgresql_engine.dispose()\n",
    "\n",
    "print(\"Proceso completado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
